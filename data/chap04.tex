\chapter{实验验证与分析}
\label{cha:exp}
在实验中，本文提出的方法在COCO2017\cite{lin2014microsoft}验证数据集上达到$46.7mAP$的准确度，相比基准方法提高了$5.5mAP$，证明本文提出的融合实例分割的多人姿态优化模块能够改善多人姿态估计网络的性能。本文通过设计自对比消融实验，证明本文提出弱监督下的空间注意力以及对应的网络结构能够更好地解决多人场景中的互遮挡问题，同时优化实例分割。
\section{数据集与评价指标}
\label{sec:dataset}
COCO2017数据集\cite{lin2014microsoft}包含了15万个人体以及将近170万个关键点信息。本文在使用该数据集时，对数据集中的关键点标注信息进行了清洗。本文将小于3个关键点的数据过滤，在训练数据集中选出了满足要求的26万条训练数据以及用于验证的1.1万条数据。每条数据由关键点信息以及目标框组成。本文使用数据集中的关键点、人体实例分割以及目标框的标注信息整体训练网络。

为验证在\ref{sec:refine}节中所提出的网络结构，本文使用平均准确度(mAP, mean Average Precision)\cite{zhu2004recall}作为评价指标，设计消融自对比实验与性能对比实验。在实验中本文使用了COCO2017验证数据集作为本文测试数据来源。平均准确度指标旨在统计一定容忍度下关键点的命中情况，通过计算交并比(IoU, Intersection over Union)求得不同物体关键点相似度(OKS，Object Key-point Similarity)\footnote{物体关键点相似度从0.5取值至0.95，间隔为0.01。}下的准确率，并对这些准确率进行积分得到最终平均准确度\cite{ruggero2017benchmarking}。

% TODO:	对比度调整
\begin{figure}
	\centering
	\includegraphics[width=0.6\linewidth]{OKS.png}
	\caption{物体关键点相似度图示\cite{ruggero2017benchmarking}}
	\label{fig:oksfigure}
\end{figure}

如图\ref{fig:oksfigure}中所示，物体关键点在计算交并比时，需要设置关键点的容许度半径。根据人眼对于关键点的识别偏差，不同关键点对应的容许度半径不同。在图\ref{fig:oksfigure}中，手腕与眼睛的预测关键点与真值的距离相当，然而评价标准给出的命中判定却不相同。由于人类对眼睛关键点的标注方差更小，对手腕关键点的标注方差更大。COCO数据集根据人类对于不同关键点标注的方差大小设置容许度半径来判别关键点命中是合理的。这比一些通过标准化距离阈值来判别命中的方法，比如关键点命中概率曲线\cite{andriluka20142d}(PCK，Probability of Correct Key-point)更加科学。

\section{消融实验与分析}
\label{sec:ablation}
本节提出多种消融策略来控制优化模块中不同部件或策略的出现，通过定量指标分析与对可视化结果的定性分析，证明本文提出的融合实例分割的多人姿态估计网络能够改善姿态估计的准确度以及完整性。
\subsection{消融策略}
\label{subsec:selfstrategy}
由于本文提出一种能够融合实例分割信息的新结构，因此需要设计自对比实验以证明文章提出的结构能够改善基线方法的性能。本文中除了多任务融合+策略使用6个堆叠的优化模块\footnote{由于过多的优化模块不能帮助优化模块细化注意力(如图\ref{fig:multistageattention})，该策略中最后两个优化模块没有使用注意力机制融合两分支。}以外，其余所有方法都是用了4个堆叠的优化模块。本文通过摘除优化模块中对应的网络结构来完成用于模块验证的消融实验。
本文设计了三种自对比的网络结构策略：
\begin{itemize}
	\item \textbf{单任务无融合}：与复现基准方法相同，不使用图\ref{fig:RefineNet}中对应的注意力转换模块、分割子网，仅留下优化模块中的共享卷积层与姿态子网的简单基准网络结构。
	\item \textbf{多任务无融合}：除单任务无融合网络结构中描述的策略以外，额外使用图\ref{fig:RefineNet}中的分割子网，但不使用注意力转换模块以及两个卷积门将生成的注意力融合的多任务网络结构。
	\item \textbf{多任务融合}：使用图\ref{fig:RefineNet}中所有的卷积层，并使用弱监督下的空间注意力融合两分支特征的网络结构。
	\item \textbf{多任务融合+}：在多任务融合网络结构的基础上，加入额外后置的常规卷积优化模块来扩大网络感受野的网络结构策略。
\end{itemize}

\subsection{消融对比实验}
\label{subsec:selfeval}

本文根据\ref{subsec:selfstrategy}节中所提到的消融策略完成在COCO测试数据集上的消融性能实验。实验结果如表\ref{tab:mAPCOCOselfbenchmark}所示。

% TODO: 自对比表格数据填充
\begin{table}[ht]
	\centering
	\caption{自对比mAP评价数据}
	\label{tab:mAPCOCOselfbenchmark}
	\begin{minipage}{0.8\linewidth}
		\begin{tabular}{p{0.25\linewidth}p{0.1\linewidth}<{\centering}p{0.1\linewidth}<{\centering}p{0.1\linewidth}<{\centering}p{0.1\linewidth}<{\centering}p{0.1\linewidth}<{\centering}}
			\hline
			方法 & \multicolumn{1}{c}{$mAP$} & \multicolumn{1}{c}{$AP_{OKS=0.5}$} & \multicolumn{1}{c}{$AP_{OKS=0.75}$} 
			& \multicolumn{1}{c}{$AP_M$} & \multicolumn{1}{c}{$AP_L$} \\
			
			& \multicolumn{1}{c}{(\%)}& \multicolumn{1}{c}{(\%)}&
			\multicolumn{1}{c}{(\%)}& \multicolumn{1}{c}{(\%)}& \multicolumn{1}{c}{
				(\%)}\\
			\hline
			单任务无融合 & 41.2 & 71.3 & 45.9& 34.2& 47.4\\
			多任务无融合 & 38.8 & 78.4 & 25.6 & 30.1 & 37.7 \\
			多任务有融合 & 45.9 & 82.1 & 45.3 & 43.0 & 51.6 \\
			多任务有融合+ & \textbf{46.7} & \textbf{83.4} & \textbf{46.6} & \textbf{45.1} & \textbf{53.2} \\
			\hline
		\end{tabular}
	\end{minipage}
\end{table}

表格\ref{tab:mAPCOCOselfbenchmark}描述本方法在COCO测试数据集上的表现情况。其中，单任务无融合策略是这四种策略中的基准，因为其仅仅完成单个关键点定位任务，且没有引入注意力机制。在表\ref{tab:mAPCOCOselfbenchmark}中可以看到，多任务无融合的实验结果明显低于本文的基准方法，也就意味着简单将多任务直接使用多分支回归会影响最终关键点定位的精度。可以明显地看到，在多任务无融合策略下，高精度阈值下的准确率明显下降了。

在使用融合，即使用空间注意力连接两任务的策略下，网络在高精度要求下的准确度大幅提升。这得益于多任务的损失函数可以通过不同分支分散分散回传梯度以使网络更好地收敛。与基准方法对比，网络能够更好地融合实例分割，让多任务融合优化策略下的关键点检测结果较基准方法中给出的有所提高， 证明使用注意力连接的优化模块比一般的多任务分支网络性能能更好，同时验证使用优化模块来加入实例分割信息能够有效改善关键点行为的性能。

\subsection{注意力可视化}
\label{sec:weaksuperatten}
本文将网络中输出的空间注意力可视化，并与原图混合得到了最终的可视化结果。由于空间注意力是单通道热图，因此本文使用了Plasma方式映射颜色空间，得到了在图\ref{fig:attenvis}右侧的可视化结果。如图\ref{fig:attenvis}中所示，注意力能够较为明确地给出遮挡人轮廓边界。对于被遮挡人不可见身体区域，空间注意力也能给出一定的响应。

\begin{figure}[H]
	\centering
	\begin{subfigure}{0.3\linewidth}
		\includegraphics[width=\linewidth, trim=100 50 100 50,clip]{60507.png}
		\caption{原始图像}
	\end{subfigure}
	\begin{subfigure}{0.3\textwidth}
		\centering
		\begin{subfigure}{\linewidth}
			\includegraphics[width=\linewidth, trim=100 50 100 50,clip]{60507_insid1_stage1_atten.png}
		\end{subfigure}
		\vskip2pt
		\begin{subfigure}{\linewidth}
			\includegraphics[width=\linewidth, trim=100 50 100 50,clip]{60507_insid1_stage2_atten.png}
		\end{subfigure}
		\vskip2pt
		\begin{subfigure}{\linewidth}
			\includegraphics[width=\linewidth, trim=100 50 100 50,clip]{60507_insid1_stage3_atten.png}
		\end{subfigure}
		\caption{遮挡人}
	\end{subfigure}
	\begin{subfigure}{0.3\textwidth}
		\centering
		\begin{subfigure}{\linewidth}
			\includegraphics[width=\linewidth, trim=100 50 100 50,clip]{60507_insid12_stage1_atten.png}
		\end{subfigure}
		\vskip2pt
		\begin{subfigure}{\linewidth}
			\includegraphics[width=\linewidth, trim=100 50 100 50,clip]{60507_insid12_stage2_atten.png}
		\end{subfigure}
		\vskip2pt
		\begin{subfigure}{\linewidth}
			\includegraphics[width=\linewidth, trim=100 50 100 50,clip]{60507_insid12_stage3_atten.png}
		\end{subfigure}
		\caption{被遮挡人}
	\end{subfigure}
	\begin{minipage}{0.05\linewidth}
		\rotatebox[origin=c]{90}{\centering 阶段2}
		
		\vskip2cm
		\rotatebox[origin=c]{90}{\centering 阶段3}
		
		\vskip2cm
		\rotatebox[origin=c]{90}{\centering 阶段4}
	\end{minipage}
	\caption{在$\alpha=0.1$遮挡情况下的空间注意力可视化结果}
	\label{fig:attenvis}
\end{figure}

从图\ref{fig:attenvis}中可以看出，多阶段优化模块的堆叠设计对注意力生成的轮廓有较为明显的影响。随着阶段增加，注意力逐渐收束且趋于完整。在第四阶段，网络对被遮挡人生成的注意力明显排除了遮挡人对应的区域。与此同时，对遮挡人生成的注意力逐级弱化了在被遮挡人手臂与腿部区域的响应，从而让姿态分支给出更加精确完整的的多人姿态检测结果。

在全局损失函数(公式\eqref{detection_loss})中不同的$\alpha$会影响注意力的生成。根据\ref{subsec:gradient}节中的推导，更低的$\alpha$会引导注意力在训练过程中缺少来自实例分割的引导。这会让注意力关注的区域更加零散，使其难以引导关键点分支划分人体区域。本文在使用不同$\alpha$取值下训练网络，对比不同$\alpha$对注意力区域生成的影响。如图\ref{fig:attenalpha}所示，在$\alpha=0.1$下训练的网络生成的空间注意力，不论从精细程度还是完整程度都优于$\alpha=0.01$下训练得到网络生成的结果。

\begin{figure}[H]
	\centering
	\begin{subfigure}{0.3\textwidth}
		\centering
		\begin{subfigure}{\linewidth}
			\includegraphics[width=\linewidth, trim=100 50 100 50,clip]{60507_insid1_stage3_atten.png}
		\end{subfigure}
		\vskip2pt
		\begin{subfigure}{\linewidth}
			\includegraphics[width=\linewidth, trim=100 50 100 50,clip]{60507_insid12_stage3_atten.png}
		\end{subfigure}
		\caption{$\alpha=0.1$}
	\end{subfigure}
	\begin{subfigure}{0.3\textwidth}
		\centering
		\begin{subfigure}{\linewidth}
			\includegraphics[width=\linewidth, trim=100 50 100 50,clip]{60507_insid1_stage1_atten_alpha.png}
		\end{subfigure}
		\vskip2pt
		\begin{subfigure}{\linewidth}
			\includegraphics[width=\linewidth, trim=100 50 100 50,clip]{60507_insid12_stage1_atten_alpha.png}
		\end{subfigure}
		\caption{$\alpha=0.01$}
	\end{subfigure}
	\begin{minipage}{0.05\linewidth}
		\rotatebox[origin=c]{90}{\centering 遮挡人}
		
		\vskip2cm
		\rotatebox[origin=c]{90}{\centering 被遮挡人}
	\end{minipage}
	\caption{在不同$\alpha$取值下训练得到的遮挡情况下的空间注意力可视化结果}
	\label{fig:attenalpha}
\end{figure}

同时，通过实验发现，注意力在无法区分单个人体区域时，会较为明显地影响关键点的定位结果。如图\ref{fig:failcase}所示，在被遮挡人可见身体部分过少的情况下，网络难以对不同人体给出显著的实例划分。图中被遮挡人的手肘和两个脚踝对关注遮挡人的注意力生成造成干扰。同时，关注被遮挡人的注意力受到遮挡人头部、肩部以及跨部的干扰，导致将遮挡人的躯干部分归入了被遮挡人的划分当中。在过多遮挡场景中给出实例划分一直是一项具有挑战的任务。众多实例分割方法与多人姿态估计方法都难以在极端遮挡的场景中提取姿态信息。本文提出的注意力无法更好地解决在极端场景下的姿态提取。由于缺乏可见人体躯干区域的特征，自生成的空间注意力无法将两人分开。但在轻度或中度遮挡的情况下，本文方法仍拥有划分人体实例的能力。

\begin{figure}[H]
	\centering
	\begin{subfigure}[t]{0.22\textwidth}
		\centering
		\begin{subfigure}[t]{\linewidth}
			\includegraphics[width=\linewidth]{872.png}
		\end{subfigure}
		\vskip2pt
		\begin{subfigure}[t]{\linewidth}
			\includegraphics[width=\linewidth]{872_insid-1_stage3_keypoint.png}
			\caption{输入图像与姿态}
		\end{subfigure}
	\end{subfigure}
	\begin{subfigure}[t]{0.22\textwidth}
		\centering
		\begin{subfigure}[t]{\linewidth}
			\includegraphics[width=\linewidth]{872_insid1_stage1_atten.png}
		\end{subfigure}
		\vskip2pt
		\begin{subfigure}[t]{\linewidth}
			\includegraphics[width=\linewidth]{872_insid0_stage1_atten.png}
			\caption{阶段2}
		\end{subfigure}
	\end{subfigure}
	\begin{subfigure}[t]{0.22\textwidth}
		\centering
		\begin{subfigure}[t]{\linewidth}
			\includegraphics[width=\linewidth]{872_insid1_stage2_atten.png}
		\end{subfigure}
		\vskip2pt
		\begin{subfigure}[t]{\linewidth}
			\includegraphics[width=\linewidth]{872_insid0_stage2_atten.png}
			\caption{阶段3}
		\end{subfigure}
	\end{subfigure}
	\begin{subfigure}[t]{0.22\textwidth}
		\centering
		\begin{subfigure}[t]{\linewidth}
			\includegraphics[width=\linewidth]{872_insid1_stage3_atten.png}
		\end{subfigure}
		\vskip2pt
		\begin{subfigure}[t]{\linewidth}
			\includegraphics[width=\linewidth]{872_insid0_stage3_atten.png}
			\caption{阶段4}
		\end{subfigure}
	\end{subfigure}
	\begin{minipage}{0.05\linewidth}
		\rotatebox[origin=c]{90}{\centering 遮挡人}
		
		\vskip2cm
		\rotatebox[origin=c]{90}{\centering 被遮挡人}
	\end{minipage}
	\caption{极端遮挡场景下的注意力可视化结果}
	\label{fig:failcase}
\end{figure}


\section{性能对比与分析}
\label{sec:perfcompare}
本节通过对比本文方法与现有方法在COCO2017验证数据集上mAP指标的表现，来对比网络与现有方法的性能，并给出结果分析，尝试从性能对比结果验证网络结构设计的优势。本文选取自顶向下结构的堆叠沙漏模型作为性能试验中的对比方法。
% TODO: 比较表格
\begin{table*}[ht]
	\centering
	\caption{COCO测试集的模型性能对比}
	\label{tab:mAPCOCObenchmark}
	\begin{minipage}[t]{0.8\linewidth}
		\begin{tabular}{p{0.25\linewidth}p{0.1\linewidth}<{\centering}p{0.1\linewidth}<{\centering}p{0.1\linewidth}<{\centering}p{0.1\linewidth}<{\centering}p{0.1\linewidth}<{\centering}}
			\hline
			方法 & \multicolumn{1}{c}{$mAP$} & \multicolumn{1}{c}{$AP_{OKS=0.5}$} & \multicolumn{1}{c}{$AP_{OKS=0.75}$}
			& \multicolumn{1}{c}{$AP_M$} & \multicolumn{1}{c}{$AP_L$} \\
			
			& \multicolumn{1}{c}{(\%)}& \multicolumn{1}{c}{(\%)}&
			\multicolumn{1}{c}{(\%)}& \multicolumn{1}{c}{(\%)}& \multicolumn{1}{c}{
				(\%)}\\
			\hline
			堆叠沙漏网络\cite{newell2016stacked} & 46.0 & 74.6 & \textbf{48.4} & 38.8  & \textbf{55.6} \\
			本文复现 & 41.2 & 71.3 & 45.9 & 34.2 & 47.4 \\
			本文方法$^1$ & 45.9 & 82.1 & 45.3 & 43.0 & 51.6 \\
			本文方法+ $^2$ & \textbf{46.7} & \textbf{83.4} & 46.6 & \textbf{45.1} & 53.2 \\
			\hline
		\end{tabular}\\[2pt]
		\noindent\rule{0.25\linewidth}{1pt} \\
		\footnotesize
		1: 使用直接连接的4个堆叠的优化模块，在本文提出的整体训练策略下收敛的模型。\\
		2: 为了增加网络感受野而使用后置的类似基准方法中出现的优化模块，在本文提出的整体训练策略下收敛的模型。
	\end{minipage}
\end{table*}

与堆叠沙漏网络相比，使用本文提出的优化模块能够显著改善关键点在$AP_{OKS=0.5}$的得分($7.5AP$)。这部分的提升主要是来自空间注意力提供的对人体的精确划分，使得给出的姿态估计更加完整。同时，本文方法在对小目标的姿态检测结果性能$AP_M$上性能较堆叠沙漏网络提高了$4.2AP$。而之后在此基础上额外增加优化模块的本文方法+在原有策略基础上提升$0.8mAP$，在$AP_{OKS=0.5}$与$AP_M$指标上比沙漏网络分别高出$8.8AP$与$6.3AP$。虽然两种优化策略下模型在$AP_{OKS=0.75}$与$AP_L$的指标上超过了复现方法，但不优于沙漏网络给出的评价结果。整体而言，本文方法在$AP$指标上比现有的自顶向下的堆叠沙漏网络高出$0.7mAP$，并能够给出更加完整的姿态估计结果。

在表\ref{tab:mAPCOCObenchmark}中，本文在宽松条件，即$OKS=0.5$下，关键点准确度明显优于本文复现的自顶向下框架以及堆叠沙漏网络给出的结果。使用弱监督学习方法训练的空间注意力能够帮助网络生成更加紧凑的姿态估计。同时在小目标检测\footnote{在COCO数据集中，小目标通常指边界框面积小于$64^2$的目标。}中明显优于传统的自顶向下的方法。大目标中出现的性能损失可能来源于直接的特征剪裁与下采样方法。在其他的自顶向下方法中，普遍采取的特征提取方法是将原图像根据检测框裁剪，再送入姿态估计网络。本结构中使用的剪裁策略是直接使用特征进行剪裁。这会在保留小尺寸目标对应特征完整性的同时，一定程度损失大尺寸目标的特征信息，因此可能会造成在更大尺寸图像上的姿态估计结果精度下降的问题。同时，本文方法在高精度指标下略微低于对比方法。这可能是由于现有的注意力生成结构仍然无法完全分散回传梯度，导致网络在多任务损失函数下难以收敛至最优结果。整体层面上，本文方法优于基线方法与堆叠沙漏网络。


\section{视觉效果与分析}
\label{sec:demo}

\begin{figure}[H]
	\centering
	\begin{minipage}[t]{\linewidth}
		\centering
		\begin{subfigure}[b]{0.23\linewidth}
			\includegraphics[width=\linewidth]{885.png}
		\end{subfigure}
		\begin{subfigure}[b]{0.23\linewidth}
			\includegraphics[width=\linewidth]{885_insid-1_stage3_atten.png}
		\end{subfigure}
		\begin{subfigure}[b]{0.23\linewidth}
			\includegraphics[width=\linewidth]{885_insid-1_mask.png}
		\end{subfigure}
		\begin{subfigure}[b]{0.23\linewidth}
			\includegraphics[width=\linewidth]{885_insid-1_stage5_keypoint.png}
		\end{subfigure}
		
		\vskip5pt
		\begin{subfigure}[b]{0.23\linewidth}
			\includegraphics[width=\linewidth]{1000.png}
		\end{subfigure}
		\begin{subfigure}[b]{0.23\linewidth}
			\includegraphics[width=\linewidth]{1000_insid-1_stage3_atten.png}
		\end{subfigure}
		\begin{subfigure}[b]{0.23\linewidth}
			\includegraphics[width=\linewidth]{1000_insid-1_mask.png}
		\end{subfigure}
		\begin{subfigure}[b]{0.23\linewidth}
			\includegraphics[width=\linewidth]{1000_insid-1_stage5_keypoint.png}
		\end{subfigure}
		
		\vskip5pt
		\begin{subfigure}[b]{0.23\linewidth}
			\includegraphics[width=\linewidth]{13729.png}
		\end{subfigure}
		\begin{subfigure}[b]{0.23\linewidth}
			\includegraphics[width=\linewidth]{13729_insid-1_stage3_atten.png}
		\end{subfigure}
		\begin{subfigure}[b]{0.23\linewidth}
			\includegraphics[width=\linewidth]{13729_insid-1_mask.png}
		\end{subfigure}
		\begin{subfigure}[b]{0.23\linewidth}
			\includegraphics[width=\linewidth]{13729_insid-1_stage5_keypoint.png}
		\end{subfigure}
		
		\vskip5pt
		\begin{subfigure}[b]{0.23\linewidth}
			\includegraphics[width=\linewidth]{18491.png}
		\end{subfigure}
		\begin{subfigure}[b]{0.23\linewidth}
			\includegraphics[width=\linewidth]{18491_insid-1_stage3_atten.png}
		\end{subfigure}
		\begin{subfigure}[b]{0.23\linewidth}
			\includegraphics[width=\linewidth]{18491_insid-1_mask.png}
		\end{subfigure}
		\begin{subfigure}[b]{0.23\linewidth}
			\includegraphics[width=\linewidth]{18491_insid-1_stage5_keypoint.png}
		\end{subfigure}
		
		\vskip5pt
		\begin{subfigure}[b]{0.23\linewidth}
			\includegraphics[width=\linewidth]{38829.png}
		\end{subfigure}
		\begin{subfigure}[b]{0.23\linewidth}
			\includegraphics[width=\linewidth]{38829_insid-1_stage3_atten.png}
		\end{subfigure}
		\begin{subfigure}[b]{0.23\linewidth}
			\includegraphics[width=\linewidth]{38829_insid-1_mask.png}
		\end{subfigure}
		\begin{subfigure}[b]{0.23\linewidth}
			\includegraphics[width=\linewidth]{38829_insid-1_stage5_keypoint.png}
		\end{subfigure}
		
		\vskip5pt
		\begin{subfigure}[b]{0.23\linewidth}
			\includegraphics[width=\linewidth]{53626.png}
		\end{subfigure}
		\begin{subfigure}[b]{0.23\linewidth}
			\includegraphics[width=\linewidth]{53626_insid-1_stage3_atten.png}
		\end{subfigure}
		\begin{subfigure}[b]{0.23\linewidth}
			\includegraphics[width=\linewidth]{53626_insid-1_mask.png}
		\end{subfigure}
		\begin{subfigure}[b]{0.23\linewidth}
			\includegraphics[width=\linewidth]{53626_insid-1_stage5_keypoint.png}
		\end{subfigure}
		
		\vskip5pt
		\begin{subfigure}[b]{0.23\linewidth}
			\includegraphics[width=\linewidth]{68387.png}
			\caption{输入图像}
		\end{subfigure}
		\begin{subfigure}[b]{0.23\linewidth}
			\includegraphics[width=\linewidth]{68387_insid-1_stage3_atten.png}
			\caption{空间注意力}
		\end{subfigure}
		\begin{subfigure}[b]{0.23\linewidth}
			\includegraphics[width=\linewidth]{68387_insid-1_mask.png}
			\caption{实例分割}
		\end{subfigure}
		\begin{subfigure}[b]{0.23\linewidth}
			\includegraphics[width=\linewidth]{68387_insid-1_stage5_keypoint.png}
			\caption{关键点检测}
		\end{subfigure}
	\end{minipage}
	\caption{本文方法得到的视觉效果图-第1组}
	\label{fig:megavis_a}
\end{figure}

\begin{figure}[H]
	\centering
	\begin{minipage}[t]{\linewidth}
		\centering
		\begin{subfigure}[b]{0.23\linewidth}
			\includegraphics[width=\linewidth]{80659.png}
		\end{subfigure}
		\begin{subfigure}[b]{0.23\linewidth}
			\includegraphics[width=\linewidth]{80659_insid-1_stage3_atten.png}
		\end{subfigure}
		\begin{subfigure}[b]{0.23\linewidth}
			\includegraphics[width=\linewidth]{80659_insid-1_mask.png}
		\end{subfigure}
		\begin{subfigure}[b]{0.23\linewidth}
			\includegraphics[width=\linewidth]{80659_insid-1_stage5_keypoint.png}
		\end{subfigure}
		
		\vskip5pt
		\begin{subfigure}[b]{0.23\linewidth}
			\includegraphics[width=\linewidth]{81988.png}
		\end{subfigure}
		\begin{subfigure}[b]{0.23\linewidth}
			\includegraphics[width=\linewidth]{81988_insid-1_stage3_atten.png}
		\end{subfigure}
		\begin{subfigure}[b]{0.23\linewidth}
			\includegraphics[width=\linewidth]{81988_insid-1_mask.png}
		\end{subfigure}
		\begin{subfigure}[b]{0.23\linewidth}
			\includegraphics[width=\linewidth]{81988_insid-1_stage5_keypoint.png}
		\end{subfigure}
		
		\vskip5pt
		\begin{subfigure}[b]{0.23\linewidth}
			\includegraphics[width=\linewidth]{90891.png}
		\end{subfigure}
		\begin{subfigure}[b]{0.23\linewidth}
			\includegraphics[width=\linewidth]{90891_insid-1_stage3_atten.png}
		\end{subfigure}
		\begin{subfigure}[b]{0.23\linewidth}
			\includegraphics[width=\linewidth]{90891_insid-1_mask.png}
		\end{subfigure}
		\begin{subfigure}[b]{0.23\linewidth}
			\includegraphics[width=\linewidth]{90891_insid-1_stage5_keypoint.png}
		\end{subfigure}
		
		\vskip5pt
		\begin{subfigure}[b]{0.23\linewidth}
			\includegraphics[width=\linewidth]{196141.png}
		\end{subfigure}
		\begin{subfigure}[b]{0.23\linewidth}
			\includegraphics[width=\linewidth]{196141_insid-1_stage3_atten.png}
		\end{subfigure}
		\begin{subfigure}[b]{0.23\linewidth}
			\includegraphics[width=\linewidth]{196141_insid-1_mask.png}
		\end{subfigure}
		\begin{subfigure}[b]{0.23\linewidth}
			\includegraphics[width=\linewidth]{196141_insid-1_stage5_keypoint.png}
		\end{subfigure}
		
		\vskip5pt
		\begin{subfigure}[b]{0.23\linewidth}
			\includegraphics[width=\linewidth]{216296.png}
		\end{subfigure}
		\begin{subfigure}[b]{0.23\linewidth}
			\includegraphics[width=\linewidth]{216296_insid-1_stage3_atten.png}
		\end{subfigure}
		\begin{subfigure}[b]{0.23\linewidth}
			\includegraphics[width=\linewidth]{216296_insid-1_mask.png}
		\end{subfigure}
		\begin{subfigure}[b]{0.23\linewidth}
			\includegraphics[width=\linewidth]{216296_insid-1_stage5_keypoint.png}
		\end{subfigure}
		
		\vskip5pt
		\begin{subfigure}[b]{0.23\linewidth}
			\includegraphics[width=\linewidth]{269316.png}
		\end{subfigure}
		\begin{subfigure}[b]{0.23\linewidth}
			\includegraphics[width=\linewidth]{269316_insid-1_stage3_atten.png}
		\end{subfigure}
		\begin{subfigure}[b]{0.23\linewidth}
			\includegraphics[width=\linewidth]{269316_insid-1_mask.png}
		\end{subfigure}
		\begin{subfigure}[b]{0.23\linewidth}
			\includegraphics[width=\linewidth]{269316_insid-1_stage5_keypoint.png}
		\end{subfigure}
		
		\vskip5pt
		\begin{subfigure}[b]{0.23\linewidth}
			\includegraphics[width=\linewidth]{323799.png}
			\caption{输入图像}
		\end{subfigure}
		\begin{subfigure}[b]{0.23\linewidth}
			\includegraphics[width=\linewidth]{323799_insid-1_stage3_atten.png}
			\caption{空间注意力}
		\end{subfigure}
		\begin{subfigure}[b]{0.23\linewidth}
			\includegraphics[width=\linewidth]{323799_insid-1_mask.png}
			\caption{实例分割}
		\end{subfigure}
		\begin{subfigure}[b]{0.23\linewidth}
			\includegraphics[width=\linewidth]{323799_insid-1_stage5_keypoint.png}
			\caption{关键点检测}
		\end{subfigure}
	\end{minipage}
	\caption{本文方法得到的视觉效果图-第2组}
	\label{fig:megavis_b}
\end{figure}

本文通过大量定量实验与定性实验证明文章提出的网络结构以及训练方式能够有效地融合实例分割与姿态估计的信息，并通过弱监督学习训练的空间注意力改善两任务中特征的融合与表达。本文提出的优化模块能够在较好地给出姿态估计与分割结果的同时，一定程度上改善多人场景下的互遮挡问题。

本文将部分可视化效果在图\ref{fig:megavis_a}与图\ref{fig:megavis_b}中展示。为凸显实例分割的交叠，本文使用了加性融合的方法对实例分割结果进行可视化。同时为使软注意力的可视化结果更加视觉友好，本文使用最大值合并的方式混合不同实例的空间注意力可视化结果。本文方法生成的注意力能够在多人场景中给出完整的实例划分，达到预期效果。同时，网络通过注意力机制能够估计不同人体实例之间的关系，并根据该线索预测出被遮挡区域的关键点与划分。

根据图\ref{fig:megavis_a}与图\ref{fig:megavis_b}所展示的视觉结果，可以清晰地看出网络生成的空间注意力、实例分割以及关键点检测结果的关系。注意力能够帮助实例分割更多地考虑被遮挡的人体区域，同时引导关键点分支分别对不同的人体区域给出姿态估计结果。证明本文提出的基于弱监督注意力的联合优化模块能够更好地利用实例分割信息优化姿态估计结果，并反相辅助补全实例分割。


\begin{figure}[H]
	\centering
	\begin{minipage}{\linewidth}
		\centering
		\begin{subfigure}[b]{0.45\linewidth}
			\centering
			\begin{minipage}{\linewidth}
				\includegraphics[width=0.48\linewidth]{1000_insid9_stage3_keypoint_baseline.png}
				\adjustbox{width=0.48\linewidth, trim={.1\width} {.1\height} {.25\width} {.25\height},clip}
				{\includegraphics[width=\linewidth]{1000_insid9_stage3_keypoint_baseline.png}}
			\end{minipage}
		\end{subfigure}
		\begin{subfigure}[b]{0.45\linewidth}
			\centering
			\begin{minipage}{\linewidth}
				\includegraphics[width=0.48\linewidth]{1000_insid9_stage5_keypoint.png}
				\adjustbox{width=0.48\linewidth, trim={.1\width} {.1\height} {.25\width} {.25\height},clip}
				{\includegraphics[width=\linewidth]{1000_insid9_stage5_keypoint.png}}
			\end{minipage}
		\end{subfigure}

		\vskip5pt
		\begin{subfigure}[b]{0.45\linewidth}
			\centering
			\begin{minipage}{\linewidth}
				\includegraphics[width=0.48\linewidth]{6471_insid9_stage3_keypoint_baseline.png}
				\adjustbox{width=0.48\linewidth, trim=0 0 {0.35\width} {.35\height},clip}
				{\includegraphics[width=\linewidth]{6471_insid9_stage3_keypoint_baseline.png}}
			\end{minipage}
		\end{subfigure}
		\begin{subfigure}[b]{0.45\linewidth}
			\centering
			\begin{minipage}{\linewidth}
				\includegraphics[width=0.48\linewidth]{6471_insid9_stage5_keypoint.png}
				\adjustbox{width=0.48\linewidth, trim=0 0 {0.35\width} {.35\height},clip}
				{\includegraphics[width=\linewidth]{6471_insid9_stage5_keypoint.png}}
			\end{minipage}
		\end{subfigure}

		\vskip5pt
		\begin{subfigure}[b]{0.45\linewidth}
			\centering
			\begin{minipage}{\linewidth}
				\includegraphics[width=0.48\linewidth]{54593_insid3_stage3_keypoint_baseline.png}
				\adjustbox{width=0.48\linewidth, trim=0 {.2\height} {.4\width} {.2\height},clip}
				{\includegraphics[width=\linewidth]{54593_insid3_stage3_keypoint_baseline.png}}
			\end{minipage}
			\caption{基准方法\cite{wei2016convolutional}}
		\end{subfigure}
		\begin{subfigure}[b]{0.45\linewidth}
			\centering
			\begin{minipage}{\linewidth}
				\includegraphics[width=0.48\linewidth]{54593_insid3_stage5_keypoint.png}
				\adjustbox{width=0.48\linewidth, trim=0 {.2\height} {.4\width} {.2\height},clip}
				{\includegraphics[width=\linewidth]{54593_insid3_stage5_keypoint.png}}
			\end{minipage}
		\caption{本文方法}
		\end{subfigure}
	\end{minipage}
	\caption{本文方法与基准方法关键点任务对比视觉效果图}
	\label{fig:comparison_keypoint}
\end{figure}

可以看到，本文提出的注意力能够明显地引导网络生成每个实例的姿态检测结果。如图\ref{fig:comparison_keypoint}中所示，本文方法可以比基准方法更好地关注单个实例。在图\ref{fig:comparison_keypoint}的第一行可以看到，通过自生成空间注意力约束，本文方法能够给出更加规整的关键点预测结果，并将结果限制于有限的特定人体区域内。基准方法中给出的多人姿态估计会受到相邻实例的干扰，影响关键点结果的完整性。此外，对于一些完全遮挡下的人体区域，本文方法可以通过注意力生成的关注区域引导姿态分支给出姿态估计，例如图\ref{fig:comparison_keypoint}中第三行图中所示。

同时，使用注意力生成的实例分割能够在一些场合中给出有交叠的分割结果。如图\ref{fig:comparison_mask}所示，实例分割结果相比于基准方法能够更多地考虑人体全局的特征。在第一行中被手臂遮挡的人体部位在基准方法给出的结果中是上下分离的，并且还出现下半身缺失分割的情况，而在本文方法中，不仅给出了大致结果，同时还连接了一部分断开的身体部分。如图\ref{fig:comparison_mask}中的第二行所示，本文方法给出的实例分割结果对遮挡情况的应对相比基准方法得到了明显的改善。同时，由于本文将关键点信息特征引入实例分割任务中，因此本文方法中的实例分割结果也能够考虑人体姿态的结构帮助生成分割结果。

\begin{figure}[H]
	\centering
	\begin{minipage}{\linewidth}
		\centering
		\begin{subfigure}[b]{0.45\linewidth}
			\begin{minipage}{\linewidth}
				\centering
				\includegraphics[width=0.48\linewidth]{13729_insid-1_mask_poly_baseline.png}
				\adjustbox{width=0.48\linewidth, trim=0 {.3\height} {0.45\width} {.15\height},clip}%
				{\includegraphics[width=\linewidth]{13729_insid-1_mask_poly_baseline.png}}
			\end{minipage}
		\end{subfigure}
		\begin{subfigure}[b]{0.45\linewidth}
			\begin{minipage}{\linewidth}
				\centering
				\includegraphics[width=0.48\linewidth]{13729_insid-1_mask_poly.png}
				\adjustbox{width=0.48\linewidth, trim=0 {.3\height} {0.45\width} {.15\height},clip}%
				{\includegraphics[width=\linewidth]{13729_insid-1_mask_poly.png}}
			\end{minipage}
		\end{subfigure}

		\vskip5pt
		\begin{subfigure}[b]{0.45\linewidth}
			\begin{minipage}{\linewidth}
				\centering
				\adjustbox{width=0.48\linewidth, trim={.15\width} {.15\height} {0.15\width} {.15\height},clip}%
				{\includegraphics{60507_insid-1_mask_poly_baseline.png}}
				\adjustbox{width=0.48\linewidth, trim={.35\width} {.35\height} {0.35\width} {.35\height},clip}%
				{\includegraphics{60507_insid-1_mask_poly_baseline.png}}
			\end{minipage}
		\end{subfigure}
		\begin{subfigure}[b]{0.45\linewidth}
			\begin{minipage}{\linewidth}
				\centering
				\adjustbox{width=0.48\linewidth, trim={.15\width} {.15\height} {0.15\width} {.15\height},clip}%
				{\includegraphics{60507_insid-1_mask_poly.png}}
				\adjustbox{width=0.48\linewidth, trim={.35\width} {.35\height} {0.35\width} {.35\height},clip}%
				{\includegraphics{60507_insid-1_mask_poly.png}}
			\end{minipage}
		\end{subfigure}

		\vskip5pt
		\begin{subfigure}[b]{0.45\linewidth}
			\begin{minipage}{\linewidth}
				\centering
				\includegraphics[width=0.48\linewidth]{323799_insid-1_mask_poly_baseline.png}
				\adjustbox{width=0.48\linewidth, trim={.05\width} {.5\height} {0.65\width} {.2\height},clip}%
				{\includegraphics[width=\linewidth]{323799_insid-1_mask_poly_baseline.png}}
			\end{minipage}	
			\caption{基准方法\cite{He2017Mask}}
		\end{subfigure}
		\begin{subfigure}[b]{0.45\linewidth}
			\begin{minipage}{\linewidth}
				\centering
				\includegraphics[width=0.48\linewidth]{323799_insid-1_mask_poly.png}
				\adjustbox{width=0.48\linewidth, trim={.05\width} {.5\height} {0.65\width} {.2\height},clip}%
				{\includegraphics[width=\linewidth]{323799_insid-1_mask_poly.png}}
			\end{minipage}	
			\caption{本文方法}
		\end{subfigure}
	\end{minipage}
	\caption{本文方法与基准方法实例分割对比视觉效果图}
	\label{fig:comparison_mask}
\end{figure}


\section{本章小结}
本节中，文章在COCO2017数据集上对比了现有方法与本文方法的性能指标，并通过设计多个对比消融实验分别证明了本文中提出的优化模块以及损失函数平衡策略的有效性。通过大量图例以及可视化结果，展示了网络模型同时给出分割结果和姿态估计结果的性能，并证明了本文提出弱监督下空间注意力的有效性。